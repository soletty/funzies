# Assembly-Viewer Interactive Evolution — Architecture & Implementation Plan

## The Core Insight

The assembly-viewer is currently a static renderer. The highest-leverage change is making it a thin bridge between the browser and Claude Code — keeping all intelligence in Claude Code, all persistence in the file system, and adding just enough JavaScript to connect the user's follow-up questions to Claude Code's streaming responses.

No framework. No build step for client-side code. No database. The existing HTTP server, the existing workspace directory, and ~300 lines of new code.

---

## Architecture

```
Browser (vanilla JS)          Viewer Server (Node.js)         Claude Code (CLI)
     |                              |                              |
     |-- POST /api/follow-up ------>|                              |
     |   {question, characters,     |-- spawn('claude', [...]) --->|
     |    context, mode}            |                              |
     |                              |<--- stdout stream-json ------|
     |<---- SSE stream -------------|                              |
     |   event: exchange            |                              |
     |   data: {speaker, content}   |-- write follow-up-{ts}.md ->|
     |                              |   (to workspace dir)         |
```

**Three layers, three concerns:**
1. **Browser** — input capture, SSE consumption, DOM rendering. Vanilla JS in a `<script>` tag. ~150-200 lines.
2. **Server** — HTTP endpoint, child process management, SSE bridge, file persistence. Node.js, extends existing server. ~200 lines.
3. **Claude Code** — all AI processing. Spawned as a child process with `--output-format stream-json`. The prompt template references workspace files for character/context continuity.

---

## What to Build — V1.1

### 1. Server: Follow-up API Endpoint

Add to the existing server (`src/server/index.ts`):

**`POST /api/follow-up`**

Request body:
```json
{
  "question": "What if we added a circuit breaker here?",
  "characters": ["marcus-okonkwo", "elena-vasquez"],
  "context": {
    "page": "synthesis",
    "section": "divergence-2",
    "topic": "resilience-vs-shipping-speed"
  },
  "mode": "multi-character",
  "sessionId": "my-architecture-decision"
}
```

The `mode` field supports three values:
- `"multi-character"` (default) — Claude Code picks 2-3 relevant characters and has them respond together, preserving adversarial tension
- `"reconvene"` — Full structured mini-debate on the topic, with Socrate present
- `"ask-character"` — Single character responds (UI should label this as "one perspective, not the assembly's judgment")

Response: SSE stream.
```
event: exchange
data: {"speaker": "Marcus Okonkwo", "content": "A circuit breaker addresses the symptom..."}

event: exchange
data: {"speaker": "Elena Vasquez", "content": "Marcus, you're adding infrastructure to solve..."}

event: done
data: {"followUpFile": "follow-up-2026-02-17T14-30-00.md"}
```

**Implementation approach:**

The server spawns Claude Code as a child process:
```
claude -p "$(cat /tmp/follow-up-prompt.txt)" \
  --output-format stream-json \
  --verbose \
  --include-partial-messages \
  --max-turns 1 \
  --no-session-persistence
```

The `-p` flag runs Claude Code non-interactively (responds and exits). `--output-format stream-json` emits newline-delimited JSON events on stdout, one per token/event. Each text event has the shape: `{"type": "stream_event", "event": {"delta": {"type": "text_delta", "text": "..."}}}`. The `--verbose` flag enables full turn output, and `--include-partial-messages` gives token-level streaming.

Alternative: the Claude Agent SDK for TypeScript (`@anthropic-ai/agent-sdk`) provides a programmatic API that avoids subprocess management entirely. For V1.1, the CLI subprocess is simpler. If the project scales, the SDK is the cleaner long-term path.

The prompt is generated from a template that includes:
- The character profiles from the workspace (`characters.md`)
- The relevant synthesis section
- The user's question
- Instructions to respond in-character, maintaining framework positions

The server reads Claude Code's stdout line by line, parses the JSON events, extracts text content, and forwards it as SSE events to the browser. When the stream ends, the server writes the complete response to the workspace directory.

### 2. Client: Follow-up UI Component

Added to the HTML generated by the renderer — a follow-up input appears on synthesis and debate pages.

**The input:**
```html
<div class="follow-up-container">
  <div class="follow-up-responses" id="follow-up-responses">
    <!-- Persisted follow-ups from previous sessions render here -->
  </div>
  <form class="follow-up-form" id="follow-up-form">
    <input type="text" placeholder="Ask a follow-up question..."
           id="follow-up-input" autocomplete="off">
    <button type="submit">Ask the Assembly</button>
  </form>
</div>
```

**The JS (~150 lines, inline `<script>` tag):**
- Form submission handler that POSTs to `/api/follow-up`
- SSE connection that renders speaker-attributed responses as they stream
- Speaker names get the character's accent color from the existing CSS color scheme
- Loading state while waiting for first event
- Error handling for Claude Code failures
- On completion, the response block becomes a permanent part of the page

**The CSS:**
- Follow-up responses styled as conversation blocks with character avatars (reusing the existing character card styling)
- Streaming text has a subtle "typing" indicator
- Completed follow-ups are visually distinct from the original assembly content

### 3. Persistence: Follow-up Files

Each completed follow-up is written to the workspace directory:

```
assembly-workspace/my-topic/
  follow-ups/
    follow-up-2026-02-17T14-30-00.md
    follow-up-2026-02-17T15-45-00.md
```

Format:
```markdown
# Follow-up — 2026-02-17 14:30

**Context:** Synthesis > Divergence 2: Resilience vs. Shipping Speed
**Mode:** Multi-character
**Question:** What if we added a circuit breaker here?

---

**Marcus Okonkwo:** A circuit breaker addresses the symptom...

**Elena Vasquez:** Marcus, you're adding infrastructure to solve...
```

The viewer's scanner/parser picks these up on subsequent visits and renders them below the relevant section.

### 4. Session Awareness (Lightweight)

- **Landing page:** The viewer's index page lists workspace directories with last-modified timestamps and the topic name parsed from the directory structure. Click to open.
- **Return state:** localStorage stores `{lastSession, lastPage, scrollPosition}`. On return visit, the viewer navigates to where the user left off.
- **Implementation:** ~50 lines of JS. No server-side state.

### 5. SVG Tension Map

During the build step, the renderer generates an SVG for the tension map instead of rendering it as text. Each character is a node, each tension is a labeled edge. Purely server-generated — no client JS needed.

This is a rendering improvement, not an interactive feature. But it transforms the tension map from something users skip (a markdown table) to something they engage with (a visual graph).

---

## What NOT to Build Yet

- **Full session creation from the viewer.** Deferred to V2, gated on follow-up engagement data.
- **Interactive (clickable) tension map.** V2. The SVG is a static improvement first; make it interactive later if engagement warrants it.
- **Character evolution across sessions.** V2+. Requires solving the prompt template problem first.
- **MCP integration.** The child process spawn approach is simpler and sufficient for V1.x. MCP becomes relevant if/when the viewer needs to communicate with Claude Code through an established server rather than spawning processes.
- **Any frontend framework.** If the features in V2 genuinely require one, re-evaluate then. Don't pre-commit.

---

## Migration Path from Current State

The current viewer is a static site generator: scan → parse → render HTML → serve.

V1.1 adds to this pipeline without replacing it:
1. The scan/parse/render pipeline remains unchanged
2. The server gains new endpoints (POST /api/follow-up)
3. The rendered HTML includes a new `<script>` tag with the follow-up JS
4. The scanner learns to pick up `follow-ups/` directories
5. The renderer learns to render persisted follow-ups inline

No existing code needs significant refactoring. The changes are additive.

**File changes:**
- `src/server/index.ts` — Add POST handler, child process spawning, SSE bridging (~200 lines added)
- `src/renderer/html.ts` — Add follow-up input HTML and inline `<script>` to page templates (~100 lines added)
- `src/renderer/css/styles.css` — Add follow-up styling (~60 lines added)
- `src/scanner/index.ts` — Scan for `follow-ups/` directory (~10 lines added)
- `src/parser/index.ts` — Parse follow-up markdown files (~30 lines added)
- `src/types.ts` — Add FollowUp type (~10 lines added)
- New file: `src/server/follow-up.ts` — Follow-up request handling, prompt template generation, Claude Code spawning (~150 lines)
- New file: `src/renderer/tension-map-svg.ts` — SVG generation for tension maps (~100 lines)

**Estimated total new code: ~660 lines.** The tool goes from ~2,500 lines to ~3,160 lines. Still small. Still manageable.

---

## Prompt Template Design (The Unsolved Problem)

The follow-up feature's quality depends entirely on the prompt sent to Claude Code. This needs iteration, but here's the starting template:

```
You are continuing an Intellectual Assembly session.

CHARACTERS:
[contents of characters.md from the workspace]

CURRENT SYNTHESIS:
[contents of synthesis.md — or the relevant section if context.section is specified]

THE USER'S QUESTION:
[user's question]

RESPONSE MODE: [multi-character | reconvene | ask-character]

INSTRUCTIONS:
- Respond as the specified characters, maintaining their ideological frameworks,
  specific positions, rhetorical tendencies, and voice as defined in the character
  profiles above.
- Characters should argue FROM their frameworks. Do not homogenize their voices.
- If mode is "multi-character": have 2-3 relevant characters respond with their
  perspective. Preserve disagreement where it exists.
- If mode is "reconvene": run a structured mini-debate with Socrate intervening.
- If mode is "ask-character": respond as the specified character only.
- Format each response as: **Character Name:** [response]
```

This template is a starting point. The key risks:
1. Character voice drift — Claude may not maintain distinctive voices across follow-ups without strong character anchoring in the prompt
2. Context window limits — including full characters.md + synthesis.md may be expensive for simple questions
3. Fidelity to original positions — characters may "soften" their views in follow-up conversation vs. the original debate

These risks need testing, not design. Ship the template, observe the output quality, iterate.

---

## Decision Points Left to the User

1. **Analytics scope:** The plan includes client-side analytics stored in localStorage. Should this include any server-side logging, or keep everything browser-only?

2. **Follow-up position on the page:** Should the follow-up input appear at the bottom of every page, or only on synthesis/debate pages? Starting with synthesis/debate is safer (most relevant context), but some users might want to ask follow-ups while reading character profiles.

3. **Claude Code invocation method:** The plan uses `claude -p --output-format stream-json`. The spawned process inherits the current shell environment, so it picks up any CLAUDE.md files, MCP servers, and model configurations. However, if the viewer's server process runs in a different directory or environment than the user's terminal, configuration may differ. Consider passing `--system-prompt` or `--append-system-prompt` explicitly to ensure character fidelity. Also: the Claude Agent SDK (`@anthropic-ai/agent-sdk`) is an alternative to CLI subprocess spawning — it provides typed message objects and avoids shell management. Worth evaluating for V1.2+.

4. **The V2 gate:** The plan defers full session creation to V2, gated on "30% of sessions including at least one follow-up." Is that the right threshold? Lower means building V2 sooner; higher means more confidence before investing.
